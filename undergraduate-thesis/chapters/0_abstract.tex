%%
% BIThesis 本科毕业设计论文模板 —— 使用 XeLaTeX 编译 The BIThesis Template for Undergraduate Thesis
% This file has no copyright assigned and is placed in the Public Domain.
%%

% 中英文摘要章节
\begin{abstract}
随着社交网络、推荐系统、生物信息学等领域中图数据的动态性日益凸显，如何使机器学习模型能够在持续到达的图序列上有效学习，同时避免对已习得知识的灾难性遗忘，成为亟待解决的关键问题，即图持续学习。图持续学习的核心挑战在于，图数据中样本间存在复杂的结构依赖，其演化过程蕴含丰富的拓扑语义，这使得传统针对独立同分布数据的持续学习方法难以直接适用。

本文聚焦于将离散数学的核心工具——图编辑距离应用于图持续学习，提出了一种基于图编辑距离的动态建模新范式。图编辑距离通过一系列原子编辑操作（顶点/边的插入、删除、替换）来量化两个图之间的差异，其最小代价路径不仅提供了距离度量，更揭示了图结构演化的具体模式。这为理解动态图的渐进变化并据此设计抗遗忘机制提供了精确的数学语言。

本文的主要工作包括：首先，系统阐述了从图、子图、同构到图编辑距离的理论脉络，奠定了方法论的数学基础。其次，提出一个分层动态建模框架：1）构建动态演化量化模型，通过计算相邻图快照间的GED，生成刻画顶点活跃度与子结构持久性的拓扑语义标签，将宏观序列差异映射为微观单元的演化属性；2）基于此量化模型，创新性地提出两种持续学习策略：基于GED的经验回放 通过优先回放高持久性的核心子图来巩固长期记忆；拓扑感知的正则化 将顶点活跃度融入参数重要性估计，对稳定结构对应的模型参数施加更强保护。最后，为应对GED计算的NP-hard挑战，设计并分析了高效的近似算法（BGM-GED）及针对动态序列的增量优化策略，论证了整体框架的可行性。

本研究通过深度融合离散数学的图论原理与机器学习的前沿需求，构建了一个具有强可解释性的图持续学习框架。该框架使得模型不仅能感知变化的大小，更能理解变化的性质，从而在“记忆”与“适应”之间实现更智能的平衡，为构建稳健、高效的动态图学习系统提供了新的理论依据与方法路径。
\end{abstract}

% 如需手动控制换行连字符位置，可写 aa\-bb，详见
% https://bithesis.bitnp.net/faq/hyphen.html

% 英文摘要章节
\begin{abstractEn}
With the increasing dynamism of graph data in fields such as social networks, recommender systems, and bioinformatics, a critical challenge emerges: how to enable machine learning models to learn effectively from a continuously arriving sequence of graphs while avoiding catastrophic forgetting of previously acquired knowledge, a problem known as Graph Continual Learning (GCL). The core difficulty lies in the complex structural dependencies among samples within graph data and the rich topological semantics embedded in their evolution, which render traditional continual learning methods designed for independent and identically distributed data inadequate.

This thesis focuses on applying a core tool of discrete mathematics—Graph Edit Distance (GED)—to graph continual learning, proposing a novel dynamic modeling paradigm based on GED. GED quantifies the difference between two graphs through a series of atomic edit operations (vertex/edge insertion, deletion, substitution). Its minimum-cost edit path not only provides a distance measure but, more importantly, reveals the specific patterns of graph structural evolution. This offers a precise mathematical language for understanding the gradual changes in dynamic graphs and designing anti-forgetting mechanisms accordingly.

The main contributions of this work are as follows: Firstly, we systematically elaborate the theoretical progression from graphs, subgraphs, and isomorphism to graph edit distance, establishing the mathematical foundation for the methodology. Secondly, we propose a hierarchical dynamic modeling framework: 1) Constructing a dynamic evolution quantification model that computes GED between consecutive graph snapshots to generate topological semantic labels, such as vertex activeness and substructure persistence, mapping macroscopic sequence differences to the evolutionary attributes of microscopic units. 2) Based on this quantitative model, we innovatively propose two continual learning strategies: GED-Guided Replay (GGR), which consolidates long-term memory by preferentially replaying high-persistence core subgraphs; and Topology-Aware Elastic Weight Consolidation (TA-EWC), which incorporates vertex activeness into parameter importance estimation to impose stronger protective constraints on model parameters corresponding to stable structures. Finally, to address the NP-hard challenge of GED computation, we design and analyze an efficient approximation algorithm (BGM-GED) along with incremental optimization strategies tailored for dynamic sequences, demonstrating the overall feasibility of the framework.

By deeply integrating the principles of graph theory from discrete mathematics with the cutting-edge demands of machine learning, this research constructs a highly interpretable framework for graph continual learning. This framework enables models not only to perceive the magnitude of change but also to understand its nature, thereby achieving a more intelligent balance between "memory" and "adaptation." It provides new theoretical foundations and methodological pathways for building robust and efficient dynamic graph learning systems.
\end{abstractEn}
